{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U tensorflow","metadata":{"execution":{"iopub.status.busy":"2023-08-27T12:53:43.721148Z","iopub.execute_input":"2023-08-27T12:53:43.722008Z","iopub.status.idle":"2023-08-27T12:54:59.256899Z","shell.execute_reply.started":"2023-08-27T12:53:43.721972Z","shell.execute_reply":"2023-08-27T12:54:59.255679Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.12.0)\nCollecting tensorflow\n  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\nCollecting keras<2.14,>=2.13.1 (from tensorflow)\n  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.0)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nCollecting tensorboard<2.14,>=2.13 (from tensorflow)\n  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow)\n  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nCollecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\nInstalling collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.6.3\n    Uninstalling typing_extensions-4.6.3:\n      Successfully uninstalled typing_extensions-4.6.3\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.12.0\n    Uninstalling tensorflow-estimator-2.12.0:\n      Successfully uninstalled tensorflow-estimator-2.12.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.12.0\n    Uninstalling keras-2.12.0:\n      Successfully uninstalled keras-2.12.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.12.3\n    Uninstalling tensorboard-2.12.3:\n      Successfully uninstalled tensorboard-2.12.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.12.0\n    Uninstalling tensorflow-2.12.0:\n      Successfully uninstalled tensorflow-2.12.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.81 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\ncudf 23.6.1 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.6.0 requires dask==2023.3.2, but you have dask 2023.7.0 which is incompatible.\ndask-cudf 23.6.1 requires dask==2023.3.2, but you have dask 2023.7.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.1 which is incompatible.\ntensorflow-decision-forests 1.4.0 requires tensorflow~=2.12.0, but you have tensorflow 2.13.0 which is incompatible.\ntensorflow-text 2.12.1 requires tensorflow<2.13,>=2.12.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.activations import selu, gelu\nfrom tensorflow.keras import layers, Sequential","metadata":{"execution":{"iopub.status.busy":"2023-08-27T01:25:40.160153Z","iopub.execute_input":"2023-08-27T01:25:40.160941Z","iopub.status.idle":"2023-08-27T01:25:43.706184Z","shell.execute_reply.started":"2023-08-27T01:25:40.160893Z","shell.execute_reply":"2023-08-27T01:25:43.704834Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess(inp, out):\n    for key, value in inp.items():\n        inp[key] = inp[key][:, tf.newaxis]\n    return inp, out\n\n# csv_ds = tf.data.experimental.make_csv_dataset(\n#     \"/kaggle/input/mmp-cleaned/data.csv\",\n#     batch_size=64, # Artificially small to make examples easier to show.\n#     label_name='HasDetections',\n#     num_epochs=1,\n#     ignore_errors=True\n# ).map(preprocess)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T01:26:10.431658Z","iopub.execute_input":"2023-08-27T01:26:10.432050Z","iopub.status.idle":"2023-08-27T01:26:10.438114Z","shell.execute_reply.started":"2023-08-27T01:26:10.432017Z","shell.execute_reply":"2023-08-27T01:26:10.436994Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# for batch, label in csv_ds.take(1):\n#     for key, value in batch.items():\n#         print(f\"{key:20s}: {value}\")\n#     print()\n#     print(f\"{'label':20s}: {label}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-27T01:26:10.736818Z","iopub.execute_input":"2023-08-27T01:26:10.737444Z","iopub.status.idle":"2023-08-27T01:26:10.742202Z","shell.execute_reply.started":"2023-08-27T01:26:10.737406Z","shell.execute_reply":"2023-08-27T01:26:10.741052Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"CATEGORICAL_FEATURES = ['ProductName', 'Platform', 'Processor', 'OsVer', 'OsPlatformSubRelease', 'SkuEdition', 'SmartScreen', 'Census_MDC2FormFactor', 'Census_DeviceFamily', 'Census_PrimaryDiskTypeName', 'Census_ChassisTypeName', 'Census_PowerPlatformRoleName', 'Census_OSVersion', 'Census_OSArchitecture', 'Census_OSBranch', 'Census_OSEdition', 'Census_OSSkuName', 'Census_OSInstallTypeName', 'Census_OSWUAutoUpdateOptionsName', 'Census_GenuineStateName', 'Census_ActivationChannel', 'Census_FlightRing', 'OsBuildLab1', 'OsBuildLab2', 'OsBuildLab3', 'OsBuildLab4']\nNUMERIC_FEATURES = ['IsBeta', 'RtpStateBitfield', 'IsSxsPassiveMode', 'AVProductStatesIdentifier', 'AVProductsInstalled', 'AVProductsEnabled', 'HasTpm', 'CountryIdentifier', 'CityIdentifier', 'OrganizationIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'OsBuild', 'OsSuite', 'IsProtected', 'AutoSampleOptIn', 'SMode', 'IeVerIdentifier', 'Firewall', 'UacLuaenable', 'Census_OEMNameIdentifier', 'Census_OEMModelIdentifier', 'Census_ProcessorCoreCount', 'Census_ProcessorManufacturerIdentifier', 'Census_ProcessorModelIdentifier', 'Census_PrimaryDiskTotalCapacity', 'Census_SystemVolumeTotalCapacity', 'Census_HasOpticalDiskDrive', 'Census_TotalPhysicalRAM', 'Census_InternalPrimaryDiagonalDisplaySizeInInches', 'Census_InternalPrimaryDisplayResolutionHorizontal', 'Census_InternalPrimaryDisplayResolutionVertical', 'Census_InternalBatteryNumberOfCharges', 'Census_OSBuildNumber', 'Census_OSBuildRevision', 'Census_OSInstallLanguageIdentifier', 'Census_OSUILocaleIdentifier', 'Census_IsPortableOperatingSystem', 'Census_IsFlightsDisabled', 'Census_ThresholdOptIn', 'Census_FirmwareManufacturerIdentifier', 'Census_FirmwareVersionIdentifier', 'Census_IsSecureBootEnabled', 'Census_IsWIMBootEnabled', 'Census_IsVirtualDevice', 'Census_IsTouchEnabled', 'Census_IsPenCapable', 'Census_IsAlwaysOnAlwaysConnectedCapable', 'Wdft_IsGamer', 'Wdft_RegionIdentifier', 'OsBuildLab0', 'Census_OSVersion1', 'Census_OSVersion2', 'Census_OSVersion3', 'AvSigVersion0', 'AvSigVersion1', 'AvSigVersion2', 'AvSigVersion3', 'AppVersion0', 'AppVersion1', 'AppVersion2', 'AppVersion3', 'EngineVersion0', 'EngineVersion1', 'EngineVersion2', 'EngineVersion3']\nNUM_CATEGORIES = {'ProductName': 6, 'Platform': 4, 'Processor': 3, 'OsVer': 58, 'OsPlatformSubRelease': 9, 'SkuEdition': 8, 'SmartScreen': 21, 'Census_MDC2FormFactor': 13, 'Census_DeviceFamily': 3, 'Census_PrimaryDiskTypeName': 4, 'Census_ChassisTypeName': 52, 'Census_PowerPlatformRoleName': 10, 'Census_OSVersion': 469, 'Census_OSArchitecture': 3, 'Census_OSBranch': 32, 'Census_OSEdition': 33, 'Census_OSSkuName': 30, 'Census_OSInstallTypeName': 9, 'Census_OSWUAutoUpdateOptionsName': 6, 'Census_GenuineStateName': 5, 'Census_ActivationChannel': 6, 'Census_FlightRing': 10, 'OsBuildLab1': 284, 'OsBuildLab2': 3, 'OsBuildLab3': 51, 'OsBuildLab4': 367}\nFEATURES = CATEGORICAL_FEATURES + NUMERIC_FEATURES","metadata":{"execution":{"iopub.status.busy":"2023-08-27T01:26:11.462821Z","iopub.execute_input":"2023-08-27T01:26:11.463562Z","iopub.status.idle":"2023-08-27T01:26:11.474303Z","shell.execute_reply.started":"2023-08-27T01:26:11.463527Z","shell.execute_reply":"2023-08-27T01:26:11.473202Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(5):\n    tabtransformer = TabTransformer(\n        numerical_features = NUMERIC_FEATURES,\n        categorical_features = CATEGORICAL_FEATURES,\n        num_categories = NUM_CATEGORIES,\n        heads=8,\n        depth=5,\n        mlp_hidden_factors = [2, 4, 8]\n    )\n\n    tabtransformer.compile(optimizer=tf.keras.optimizers.Lion(learning_rate=1e-3),\n                          loss=tf.keras.losses.BinaryCrossentropy(),\n                          metrics=['accuracy', \"Precision\", \"Recall\", \"AUC\"])\n    models.append(tabtransformer)","metadata":{"execution":{"iopub.status.busy":"2023-08-27T02:35:45.387498Z","iopub.execute_input":"2023-08-27T02:35:45.387912Z","iopub.status.idle":"2023-08-27T02:35:45.970164Z","shell.execute_reply.started":"2023-08-27T02:35:45.387879Z","shell.execute_reply":"2023-08-27T02:35:45.969052Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(layers.Layer):\n    def __init__(\n        self, embed_dim: int, num_heads: int, ff_dim: int, \n        att_dropout: float = 0.1, ff_dropout: float = 0.1\n    ):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=att_dropout)\n        self.skip1 = layers.Add()\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.ffn = Sequential([\n            layers.Dense(ff_dim, activation=gelu),\n            layers.Dropout(ff_dropout),\n            layers.Dense(embed_dim),\n        ])\n        self.skip2 = layers.Add()\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, inputs):\n        inputs = self.layernorm1(inputs)\n        attention_output = self.att(inputs, inputs)\n        attention_output = self.skip1([inputs, attention_output])   \n        feedforward_output = self.ffn(attention_output) \n        transformer_output = self.skip2([feedforward_output, attention_output])\n        transformer_output = self.layernorm2(transformer_output)\n        return transformer_output\n\n\nclass TabTransformer(tf.keras.Model):\n    def __init__(\n        self,\n        numerical_features: list = [],\n        categorical_features: list = [],\n        num_categories: dict = {},\n        depth: int = 2,\n        heads: int = 8,\n        attn_dropout: float = 0.2,\n        ff_dropout: float = 0.2,\n        mlp_hidden_factors: list = [2, 4],\n        mlp_num_factors: list = [2, 4],\n        num_final: int = 10,\n    ):\n        super(TabTransformer, self).__init__()\n        \n        self.numerical = numerical_features\n        self.categorical = categorical_features\n        \n        self.continuous_normalization = layers.LayerNormalization()\n        self.numerical_concatenation = layers.Concatenate(axis=1) # 1\n\n        self.cat_embedding_layers = [\n            layers.Embedding(\n                input_dim=num_categories[c], output_dim=32\n            ) for c in self.categorical\n        ]\n        \n        num_columns = len(self.categorical)\n        \n        self.column_embedding = layers.Embedding(\n            input_dim=num_columns, output_dim=32\n        )\n        self.column_indices = tf.range(start=0, limit=num_columns, delta=1)\n\n        self.embedded_concatenation = layers.Concatenate(axis=1)\n\n        self.transformers = []\n        for _ in range(depth):\n            self.transformers.append(\n                TransformerBlock(\n                    32, heads, 32,\n                    attn_dropout, ff_dropout,\n                )\n            )\n        self.flatten_transformer_output = layers.Flatten()\n        self.pre_mlp_concatenation = layers.Concatenate()\n\n        numerical_dim = len(self.numerical)\n        num_units = [numerical_dim // f for f in mlp_num_factors]\n        num_layers = []\n        for units in num_units:\n            num_layers.append(layers.BatchNormalization()),\n            num_layers.append(layers.Dense(units, activation=selu))\n            num_layers.append(layers.Dropout(ff_dropout))\n\n        self.num_final = Sequential(num_layers)\n        self.num_layer = layers.Dense(num_final, activation=\"relu\")\n        \n        mlp_input_dim = num_final + 32 * len(self.categorical)\n            \n        hidden_units = [mlp_input_dim // f for f in mlp_hidden_factors]\n        mlp_layers = []\n        for units in hidden_units:\n            mlp_layers.append(layers.BatchNormalization()),\n            mlp_layers.append(layers.Dense(units, activation=selu))\n            mlp_layers.append(layers.Dropout(ff_dropout))\n\n        self.mlp_final = Sequential(mlp_layers)\n        self.output_layer = layers.Dense(1, activation=\"relu\")\n\n    def call(self, inputs):\n        numerical_feature_list = [inputs[n] for n in self.numerical]\n        categorical_feature_list = [emb(inputs[c]) for emb, c in zip(self.cat_embedding_layers, self.categorical)]\n#         print(categorical_feature_list[0])\n\n        transformer_inputs = self.embedded_concatenation(categorical_feature_list)# + self.column_embedding(self.column_indices)\n        # Add column embeddings\n        transformer_inputs += self.column_embedding(self.column_indices)\n\n        for transformer in self.transformers:\n            transformer_inputs = transformer(transformer_inputs)\n\n        mlp_input = self.flatten_transformer_output(transformer_inputs)\n        \n        numerical_inputs = self.numerical_concatenation(numerical_feature_list)\n        numerical_inputs = self.continuous_normalization(numerical_inputs)\n        numerical_inputs = self.num_final(numerical_inputs)\n        numerical_inputs = self.num_layer(numerical_inputs)\n        mlp_input = self.pre_mlp_concatenation([mlp_input, numerical_inputs])\n        x = self.mlp_final(mlp_input)\n        output = self.output_layer(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-08-27T01:26:12.361366Z","iopub.execute_input":"2023-08-27T01:26:12.361750Z","iopub.status.idle":"2023-08-27T01:26:12.386051Z","shell.execute_reply.started":"2023-08-27T01:26:12.361718Z","shell.execute_reply":"2023-08-27T01:26:12.385000Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(5):\n    tabtransformer = TabTransformer(\n        numerical_features = NUMERIC_FEATURES,\n        categorical_features = CATEGORICAL_FEATURES,\n        num_categories = NUM_CATEGORIES,\n        heads=8,\n        depth=5,\n        mlp_hidden_factors = [2, 4, 8]\n    )\n\n    tabtransformer.compile(optimizer=tf.keras.optimizers.Lion(learning_rate=1e-3),\n                          loss=tf.keras.losses.BinaryCrossentropy(),\n                          metrics=['accuracy', \"Precision\", \"Recall\", \"AUC\"])\n    models.append(tabtransformer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    train_dir = \"\"\n    test_dir = \"\"\n    if (i != 4):\n        train_dir = f\"/kaggle/input/mmp-cleaned/fold{i}_train.csv\"\n        test_dir = f\"/kaggle/input/mmp-cleaned/fold{i}_test.csv\"\n    else:\n        train_dir = f\"/kaggle/input/mmp-cleaned-2/fold{i}_train.csv\"\n        test_dir = f\"/kaggle/input/mmp-cleaned-2/fold{i}_test.csv\"\n    train = tf.data.experimental.make_csv_dataset(\n        train_dir,\n        batch_size=64, # Artificially small to make examples easier to show.\n        label_name='HasDetections',\n        num_epochs=1,\n        ignore_errors=True\n        ).map(preprocess)\n    test = tf.data.experimental.make_csv_dataset(\n        test_dir,\n        batch_size=64, # Artificially small to make examples easier to show.\n        label_name='HasDetections',\n        num_epochs=1,\n        ignore_errors=True\n        ).map(preprocess) \n    models[i].fit(\n        x = train,\n        validation_data=test,\n        epochs = 1,\n        shuffle=True,)\n    del train\n    del test","metadata":{"execution":{"iopub.status.busy":"2023-08-27T02:35:45.972062Z","iopub.execute_input":"2023-08-27T02:35:45.972512Z","iopub.status.idle":"2023-08-27T12:50:26.563023Z","shell.execute_reply.started":"2023-08-27T02:35:45.972472Z","shell.execute_reply":"2023-08-27T12:50:26.560170Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/20\n111519/111519 [==============================] - 7090s 63ms/step - loss: 0.6464 - accuracy: 0.6090 - precision: 0.6215 - recall: 0.5567 - auc: 0.6604 - val_loss: 0.6384 - val_accuracy: 0.6195 - val_precision: 0.6506 - val_recall: 0.5154 - val_auc: 0.6757\nEpoch 2/20\n111519/111519 [==============================] - 6922s 62ms/step - loss: 0.6403 - accuracy: 0.6183 - precision: 0.6291 - recall: 0.5758 - auc: 0.6721 - val_loss: 0.6361 - val_accuracy: 0.6238 - val_precision: 0.6281 - val_recall: 0.6064 - val_auc: 0.6797\nEpoch 3/20\n111519/111519 [==============================] - 6924s 62ms/step - loss: 0.6460 - accuracy: 0.6095 - precision: 0.6176 - recall: 0.5744 - auc: 0.6613 - val_loss: 0.6662 - val_accuracy: 0.5863 - val_precision: 0.7652 - val_recall: 0.2486 - val_auc: 0.6691\nEpoch 4/20\n111519/111519 [==============================] - 6954s 62ms/step - loss: 0.6430 - accuracy: 0.6146 - precision: 0.6253 - recall: 0.5709 - auc: 0.6670 - val_loss: 0.6418 - val_accuracy: 0.6171 - val_precision: 0.6340 - val_recall: 0.5531 - val_auc: 0.6713\nEpoch 5/20\n111519/111519 [==============================] - 6995s 63ms/step - loss: 0.6443 - accuracy: 0.6130 - precision: 0.6220 - recall: 0.5753 - auc: 0.6649 - val_loss: 0.6408 - val_accuracy: 0.6142 - val_precision: 0.5982 - val_recall: 0.6949 - val_auc: 0.6738\nEpoch 6/20\n 33279/111519 [=======>......................] - ETA: 1:15:10 - loss: 0.6430 - accuracy: 0.6148 - precision: 0.6258 - recall: 0.5690 - auc: 0.6675","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     10\u001b[0m train \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mmake_csv_dataset(\n\u001b[1;32m     11\u001b[0m     train_dir,\n\u001b[1;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, \u001b[38;5;66;03m# Artificially small to make examples easier to show.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ignore_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     )\u001b[38;5;241m.\u001b[39mmap(preprocess)\n\u001b[1;32m     17\u001b[0m test \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mmake_csv_dataset(\n\u001b[1;32m     18\u001b[0m     test_dir,\n\u001b[1;32m     19\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, \u001b[38;5;66;03m# Artificially small to make examples easier to show.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     ignore_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\u001b[38;5;241m.\u001b[39mmap(preprocess) \n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m test\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# tabtransformer.predict(csv_ds)#, epochs=1, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}